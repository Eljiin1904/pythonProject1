<html>
<head>
<title>lexer.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
lexer.py</font>
</center></td></tr></table>
<pre><span class="s0">#</span>
<span class="s0"># Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="s0"># &lt;see AUTHORS file&gt;</span>
<span class="s0">#</span>
<span class="s0"># This module is part of python-sqlparse and is released under</span>
<span class="s0"># the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>

<span class="s2">&quot;&quot;&quot;SQL Lexer&quot;&quot;&quot;</span>

<span class="s0"># This code is based on the SqlLexer in pygments.</span>
<span class="s0"># http://pygments.org/</span>
<span class="s0"># It's separated from the rest of pygments to increase performance</span>
<span class="s0"># and to allow some customizations.</span>

<span class="s3">from </span><span class="s1">io </span><span class="s3">import </span><span class="s1">TextIOBase</span>

<span class="s3">from </span><span class="s1">sqlparse </span><span class="s3">import </span><span class="s1">tokens</span>
<span class="s3">from </span><span class="s1">sqlparse.keywords </span><span class="s3">import </span><span class="s1">SQL_REGEX</span>
<span class="s3">from </span><span class="s1">sqlparse.utils </span><span class="s3">import </span><span class="s1">consume</span>


<span class="s3">class </span><span class="s1">Lexer:</span>
    <span class="s2">&quot;&quot;&quot;Lexer 
    Empty class. Leaving for backwards-compatibility 
    &quot;&quot;&quot;</span>

    <span class="s1">@staticmethod</span>
    <span class="s3">def </span><span class="s1">get_tokens(text</span><span class="s3">, </span><span class="s1">encoding=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Return an iterable of (tokentype, value) pairs generated from 
        `text`. If `unfiltered` is set to `True`, the filtering mechanism 
        is bypassed even if filters are defined. 
 
        Also preprocess the text, i.e. expand tabs and strip it if 
        wanted and applies registered filters. 
 
        Split ``text`` into (tokentype, text) pairs. 
 
        ``stack`` is the initial stack (default: ``['root']``) 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">isinstance(text</span><span class="s3">, </span><span class="s1">TextIOBase):</span>
            <span class="s1">text = text.read()</span>

        <span class="s3">if </span><span class="s1">isinstance(text</span><span class="s3">, </span><span class="s1">str):</span>
            <span class="s3">pass</span>
        <span class="s3">elif </span><span class="s1">isinstance(text</span><span class="s3">, </span><span class="s1">bytes):</span>
            <span class="s3">if </span><span class="s1">encoding:</span>
                <span class="s1">text = text.decode(encoding)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">try</span><span class="s1">:</span>
                    <span class="s1">text = text.decode(</span><span class="s4">'utf-8'</span><span class="s1">)</span>
                <span class="s3">except </span><span class="s1">UnicodeDecodeError:</span>
                    <span class="s1">text = text.decode(</span><span class="s4">'unicode-escape'</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Expected text or file-like object, got {!r}&quot;</span><span class="s1">.</span>
                            <span class="s1">format(type(text)))</span>

        <span class="s1">iterable = enumerate(text)</span>
        <span class="s3">for </span><span class="s1">pos</span><span class="s3">, </span><span class="s1">char </span><span class="s3">in </span><span class="s1">iterable:</span>
            <span class="s3">for </span><span class="s1">rexmatch</span><span class="s3">, </span><span class="s1">action </span><span class="s3">in </span><span class="s1">SQL_REGEX:</span>
                <span class="s1">m = rexmatch(text</span><span class="s3">, </span><span class="s1">pos)</span>

                <span class="s3">if not </span><span class="s1">m:</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">isinstance(action</span><span class="s3">, </span><span class="s1">tokens._TokenType):</span>
                    <span class="s3">yield </span><span class="s1">action</span><span class="s3">, </span><span class="s1">m.group()</span>
                <span class="s3">elif </span><span class="s1">callable(action):</span>
                    <span class="s3">yield </span><span class="s1">action(m.group())</span>

                <span class="s1">consume(iterable</span><span class="s3">, </span><span class="s1">m.end() - pos - </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s3">break</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">yield </span><span class="s1">tokens.Error</span><span class="s3">, </span><span class="s1">char</span>


<span class="s3">def </span><span class="s1">tokenize(sql</span><span class="s3">, </span><span class="s1">encoding=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Tokenize sql. 
 
    Tokenize *sql* using the :class:`Lexer` and return a 2-tuple stream 
    of ``(token type, value)`` items. 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">Lexer().get_tokens(sql</span><span class="s3">, </span><span class="s1">encoding)</span>
</pre>
</body>
</html>