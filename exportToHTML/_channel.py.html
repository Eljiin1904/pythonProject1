<html>
<head>
<title>_channel.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_channel.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">collections </span><span class="s0">import </span><span class="s1">deque</span><span class="s0">, </span><span class="s1">OrderedDict</span>
<span class="s0">from </span><span class="s1">math </span><span class="s0">import </span><span class="s1">inf</span>

<span class="s0">import </span><span class="s1">attr</span>
<span class="s0">from </span><span class="s1">outcome </span><span class="s0">import </span><span class="s1">Error</span><span class="s0">, </span><span class="s1">Value</span>

<span class="s0">from </span><span class="s1">.abc </span><span class="s0">import </span><span class="s1">SendChannel</span><span class="s0">, </span><span class="s1">ReceiveChannel</span><span class="s0">, </span><span class="s1">Channel</span>
<span class="s0">from </span><span class="s1">._util </span><span class="s0">import </span><span class="s1">generic_function</span><span class="s0">, </span><span class="s1">NoPublicConstructor</span>

<span class="s0">import </span><span class="s1">trio</span>
<span class="s0">from </span><span class="s1">._core </span><span class="s0">import </span><span class="s1">enable_ki_protection</span>


<span class="s1">@generic_function</span>
<span class="s0">def </span><span class="s1">open_memory_channel(max_buffer_size):</span>
    <span class="s2">&quot;&quot;&quot;Open a channel for passing objects between tasks within a process. 
 
    Memory channels are lightweight, cheap to allocate, and entirely 
    in-memory. They don't involve any operating-system resources, or any kind 
    of serialization. They just pass Python objects directly between tasks 
    (with a possible stop in an internal buffer along the way). 
 
    Channel objects can be closed by calling `~trio.abc.AsyncResource.aclose` 
    or using ``async with``. They are *not* automatically closed when garbage 
    collected. Closing memory channels isn't mandatory, but it is generally a 
    good idea, because it helps avoid situations where tasks get stuck waiting 
    on a channel when there's no-one on the other side. See 
    :ref:`channel-shutdown` for details. 
 
    Memory channel operations are all atomic with respect to 
    cancellation, either `~trio.abc.ReceiveChannel.receive` will 
    successfully return an object, or it will raise :exc:`Cancelled` 
    while leaving the channel unchanged. 
 
    Args: 
      max_buffer_size (int or math.inf): The maximum number of items that can 
        be buffered in the channel before :meth:`~trio.abc.SendChannel.send` 
        blocks. Choosing a sensible value here is important to ensure that 
        backpressure is communicated promptly and avoid unnecessary latency; 
        see :ref:`channel-buffering` for more details. If in doubt, use 0. 
 
    Returns: 
      A pair ``(send_channel, receive_channel)``. If you have 
      trouble remembering which order these go in, remember: data 
      flows from left â†’ right. 
 
    In addition to the standard channel methods, all memory channel objects 
    provide a ``statistics()`` method, which returns an object with the 
    following fields: 
 
    * ``current_buffer_used``: The number of items currently stored in the 
      channel buffer. 
    * ``max_buffer_size``: The maximum number of items allowed in the buffer, 
      as passed to :func:`open_memory_channel`. 
    * ``open_send_channels``: The number of open 
      :class:`MemorySendChannel` endpoints pointing to this channel. 
      Initially 1, but can be increased by 
      :meth:`MemorySendChannel.clone`. 
    * ``open_receive_channels``: Likewise, but for open 
      :class:`MemoryReceiveChannel` endpoints. 
    * ``tasks_waiting_send``: The number of tasks blocked in ``send`` on this 
      channel (summing over all clones). 
    * ``tasks_waiting_receive``: The number of tasks blocked in ``receive`` on 
      this channel (summing over all clones). 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">max_buffer_size != inf </span><span class="s0">and not </span><span class="s1">isinstance(max_buffer_size</span><span class="s0">, </span><span class="s1">int):</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s3">&quot;max_buffer_size must be an integer or math.inf&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">max_buffer_size &lt; </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;max_buffer_size must be &gt;= 0&quot;</span><span class="s1">)</span>
    <span class="s1">state = MemoryChannelState(max_buffer_size)</span>
    <span class="s0">return </span><span class="s1">(</span>
        <span class="s1">MemorySendChannel._create(state)</span><span class="s0">,</span>
        <span class="s1">MemoryReceiveChannel._create(state)</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@attr.s(frozen=</span><span class="s0">True, </span><span class="s1">slots=</span><span class="s0">True</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">MemoryChannelStats:</span>
    <span class="s1">current_buffer_used = attr.ib()</span>
    <span class="s1">max_buffer_size = attr.ib()</span>
    <span class="s1">open_send_channels = attr.ib()</span>
    <span class="s1">open_receive_channels = attr.ib()</span>
    <span class="s1">tasks_waiting_send = attr.ib()</span>
    <span class="s1">tasks_waiting_receive = attr.ib()</span>


<span class="s1">@attr.s(slots=</span><span class="s0">True</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">MemoryChannelState:</span>
    <span class="s1">max_buffer_size = attr.ib()</span>
    <span class="s1">data = attr.ib(factory=deque)</span>
    <span class="s5"># Counts of open endpoints using this state</span>
    <span class="s1">open_send_channels = attr.ib(default=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">open_receive_channels = attr.ib(default=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s5"># {task: value}</span>
    <span class="s1">send_tasks = attr.ib(factory=OrderedDict)</span>
    <span class="s5"># {task: None}</span>
    <span class="s1">receive_tasks = attr.ib(factory=OrderedDict)</span>

    <span class="s0">def </span><span class="s1">statistics(self):</span>
        <span class="s0">return </span><span class="s1">MemoryChannelStats(</span>
            <span class="s1">current_buffer_used=len(self.data)</span><span class="s0">,</span>
            <span class="s1">max_buffer_size=self.max_buffer_size</span><span class="s0">,</span>
            <span class="s1">open_send_channels=self.open_send_channels</span><span class="s0">,</span>
            <span class="s1">open_receive_channels=self.open_receive_channels</span><span class="s0">,</span>
            <span class="s1">tasks_waiting_send=len(self.send_tasks)</span><span class="s0">,</span>
            <span class="s1">tasks_waiting_receive=len(self.receive_tasks)</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@attr.s(eq=</span><span class="s0">False, </span><span class="s1">repr=</span><span class="s0">False</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">MemorySendChannel(SendChannel</span><span class="s0">, </span><span class="s1">metaclass=NoPublicConstructor):</span>
    <span class="s1">_state = attr.ib()</span>
    <span class="s1">_closed = attr.ib(default=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s5"># This is just the tasks waiting on *this* object. As compared to</span>
    <span class="s5"># self._state.send_tasks, which includes tasks from this object and</span>
    <span class="s5"># all clones.</span>
    <span class="s1">_tasks = attr.ib(factory=set)</span>

    <span class="s0">def </span><span class="s1">__attrs_post_init__(self):</span>
        <span class="s1">self._state.open_send_channels += </span><span class="s4">1</span>

    <span class="s0">def </span><span class="s1">__repr__(self):</span>
        <span class="s0">return </span><span class="s3">&quot;&lt;send channel at {:#x}, using buffer at {:#x}&gt;&quot;</span><span class="s1">.format(</span>
            <span class="s1">id(self)</span><span class="s0">, </span><span class="s1">id(self._state)</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">statistics(self):</span>
        <span class="s5"># XX should we also report statistics specific to this object?</span>
        <span class="s0">return </span><span class="s1">self._state.statistics()</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">send_nowait(self</span><span class="s0">, </span><span class="s1">value):</span>
        <span class="s2">&quot;&quot;&quot;Like `~trio.abc.SendChannel.send`, but if the channel's buffer is 
        full, raises `WouldBlock` instead of blocking. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">raise </span><span class="s1">trio.ClosedResourceError</span>
        <span class="s0">if </span><span class="s1">self._state.open_receive_channels == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">trio.BrokenResourceError</span>
        <span class="s0">if </span><span class="s1">self._state.receive_tasks:</span>
            <span class="s0">assert not </span><span class="s1">self._state.data</span>
            <span class="s1">task</span><span class="s0">, </span><span class="s1">_ = self._state.receive_tasks.popitem(last=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">task.custom_sleep_data._tasks.remove(task)</span>
            <span class="s1">trio.lowlevel.reschedule(task</span><span class="s0">, </span><span class="s1">Value(value))</span>
        <span class="s0">elif </span><span class="s1">len(self._state.data) &lt; self._state.max_buffer_size:</span>
            <span class="s1">self._state.data.append(value)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">trio.WouldBlock</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">async def </span><span class="s1">send(self</span><span class="s0">, </span><span class="s1">value):</span>
        <span class="s2">&quot;&quot;&quot;See `SendChannel.send &lt;trio.abc.SendChannel.send&gt;`. 
 
        Memory channels allow multiple tasks to call `send` at the same time. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">await </span><span class="s1">trio.lowlevel.checkpoint_if_cancelled()</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">self.send_nowait(value)</span>
        <span class="s0">except </span><span class="s1">trio.WouldBlock:</span>
            <span class="s0">pass</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">await </span><span class="s1">trio.lowlevel.cancel_shielded_checkpoint()</span>
            <span class="s0">return</span>

        <span class="s1">task = trio.lowlevel.current_task()</span>
        <span class="s1">self._tasks.add(task)</span>
        <span class="s1">self._state.send_tasks[task] = value</span>
        <span class="s1">task.custom_sleep_data = self</span>

        <span class="s0">def </span><span class="s1">abort_fn(_):</span>
            <span class="s1">self._tasks.remove(task)</span>
            <span class="s0">del </span><span class="s1">self._state.send_tasks[task]</span>
            <span class="s0">return </span><span class="s1">trio.lowlevel.Abort.SUCCEEDED</span>

        <span class="s0">await </span><span class="s1">trio.lowlevel.wait_task_rescheduled(abort_fn)</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">clone(self):</span>
        <span class="s2">&quot;&quot;&quot;Clone this send channel object. 
 
        This returns a new `MemorySendChannel` object, which acts as a 
        duplicate of the original: sending on the new object does exactly the 
        same thing as sending on the old object. (If you're familiar with 
        `os.dup`, then this is a similar idea.) 
 
        However, closing one of the objects does not close the other, and 
        receivers don't get `EndOfChannel` until *all* clones have been 
        closed. 
 
        This is useful for communication patterns that involve multiple 
        producers all sending objects to the same destination. If you give 
        each producer its own clone of the `MemorySendChannel`, and then make 
        sure to close each `MemorySendChannel` when it's finished, receivers 
        will automatically get notified when all producers are finished. See 
        :ref:`channel-mpmc` for examples. 
 
        Raises: 
          trio.ClosedResourceError: if you already closed this 
              `MemorySendChannel` object. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">raise </span><span class="s1">trio.ClosedResourceError</span>
        <span class="s0">return </span><span class="s1">MemorySendChannel._create(self._state)</span>

    <span class="s0">def </span><span class="s1">__enter__(self):</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">__exit__(self</span><span class="s0">, </span><span class="s1">exc_type</span><span class="s0">, </span><span class="s1">exc_val</span><span class="s0">, </span><span class="s1">exc_tb):</span>
        <span class="s1">self.close()</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">close(self):</span>
        <span class="s2">&quot;&quot;&quot;Close this send channel object synchronously. 
 
        All channel objects have an asynchronous `~.AsyncResource.aclose` method. 
        Memory channels can also be closed synchronously. This has the same 
        effect on the channel and other tasks using it, but `close` is not a 
        trio checkpoint. This simplifies cleaning up in cancelled tasks. 
 
        Using ``with send_channel:`` will close the channel object on leaving 
        the with block. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">return</span>
        <span class="s1">self._closed = </span><span class="s0">True</span>
        <span class="s0">for </span><span class="s1">task </span><span class="s0">in </span><span class="s1">self._tasks:</span>
            <span class="s1">trio.lowlevel.reschedule(task</span><span class="s0">, </span><span class="s1">Error(trio.ClosedResourceError()))</span>
            <span class="s0">del </span><span class="s1">self._state.send_tasks[task]</span>
        <span class="s1">self._tasks.clear()</span>
        <span class="s1">self._state.open_send_channels -= </span><span class="s4">1</span>
        <span class="s0">if </span><span class="s1">self._state.open_send_channels == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">assert not </span><span class="s1">self._state.send_tasks</span>
            <span class="s0">for </span><span class="s1">task </span><span class="s0">in </span><span class="s1">self._state.receive_tasks:</span>
                <span class="s1">task.custom_sleep_data._tasks.remove(task)</span>
                <span class="s1">trio.lowlevel.reschedule(task</span><span class="s0">, </span><span class="s1">Error(trio.EndOfChannel()))</span>
            <span class="s1">self._state.receive_tasks.clear()</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">async def </span><span class="s1">aclose(self):</span>
        <span class="s1">self.close()</span>
        <span class="s0">await </span><span class="s1">trio.lowlevel.checkpoint()</span>


<span class="s1">@attr.s(eq=</span><span class="s0">False, </span><span class="s1">repr=</span><span class="s0">False</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">MemoryReceiveChannel(ReceiveChannel</span><span class="s0">, </span><span class="s1">metaclass=NoPublicConstructor):</span>
    <span class="s1">_state = attr.ib()</span>
    <span class="s1">_closed = attr.ib(default=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">_tasks = attr.ib(factory=set)</span>

    <span class="s0">def </span><span class="s1">__attrs_post_init__(self):</span>
        <span class="s1">self._state.open_receive_channels += </span><span class="s4">1</span>

    <span class="s0">def </span><span class="s1">statistics(self):</span>
        <span class="s0">return </span><span class="s1">self._state.statistics()</span>

    <span class="s0">def </span><span class="s1">__repr__(self):</span>
        <span class="s0">return </span><span class="s3">&quot;&lt;receive channel at {:#x}, using buffer at {:#x}&gt;&quot;</span><span class="s1">.format(</span>
            <span class="s1">id(self)</span><span class="s0">, </span><span class="s1">id(self._state)</span>
        <span class="s1">)</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">receive_nowait(self):</span>
        <span class="s2">&quot;&quot;&quot;Like `~trio.abc.ReceiveChannel.receive`, but if there's nothing 
        ready to receive, raises `WouldBlock` instead of blocking. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">raise </span><span class="s1">trio.ClosedResourceError</span>
        <span class="s0">if </span><span class="s1">self._state.send_tasks:</span>
            <span class="s1">task</span><span class="s0">, </span><span class="s1">value = self._state.send_tasks.popitem(last=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">task.custom_sleep_data._tasks.remove(task)</span>
            <span class="s1">trio.lowlevel.reschedule(task)</span>
            <span class="s1">self._state.data.append(value)</span>
            <span class="s5"># Fall through</span>
        <span class="s0">if </span><span class="s1">self._state.data:</span>
            <span class="s0">return </span><span class="s1">self._state.data.popleft()</span>
        <span class="s0">if not </span><span class="s1">self._state.open_send_channels:</span>
            <span class="s0">raise </span><span class="s1">trio.EndOfChannel</span>
        <span class="s0">raise </span><span class="s1">trio.WouldBlock</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">async def </span><span class="s1">receive(self):</span>
        <span class="s2">&quot;&quot;&quot;See `ReceiveChannel.receive &lt;trio.abc.ReceiveChannel.receive&gt;`. 
 
        Memory channels allow multiple tasks to call `receive` at the same 
        time. The first task will get the first item sent, the second task 
        will get the second item sent, and so on. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">await </span><span class="s1">trio.lowlevel.checkpoint_if_cancelled()</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">value = self.receive_nowait()</span>
        <span class="s0">except </span><span class="s1">trio.WouldBlock:</span>
            <span class="s0">pass</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">await </span><span class="s1">trio.lowlevel.cancel_shielded_checkpoint()</span>
            <span class="s0">return </span><span class="s1">value</span>

        <span class="s1">task = trio.lowlevel.current_task()</span>
        <span class="s1">self._tasks.add(task)</span>
        <span class="s1">self._state.receive_tasks[task] = </span><span class="s0">None</span>
        <span class="s1">task.custom_sleep_data = self</span>

        <span class="s0">def </span><span class="s1">abort_fn(_):</span>
            <span class="s1">self._tasks.remove(task)</span>
            <span class="s0">del </span><span class="s1">self._state.receive_tasks[task]</span>
            <span class="s0">return </span><span class="s1">trio.lowlevel.Abort.SUCCEEDED</span>

        <span class="s0">return await </span><span class="s1">trio.lowlevel.wait_task_rescheduled(abort_fn)</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">clone(self):</span>
        <span class="s2">&quot;&quot;&quot;Clone this receive channel object. 
 
        This returns a new `MemoryReceiveChannel` object, which acts as a 
        duplicate of the original: receiving on the new object does exactly 
        the same thing as receiving on the old object. 
 
        However, closing one of the objects does not close the other, and the 
        underlying channel is not closed until all clones are closed. (If 
        you're familiar with `os.dup`, then this is a similar idea.) 
 
        This is useful for communication patterns that involve multiple 
        consumers all receiving objects from the same underlying channel. See 
        :ref:`channel-mpmc` for examples. 
 
        .. warning:: The clones all share the same underlying channel. 
           Whenever a clone :meth:`receive`\\s a value, it is removed from the 
           channel and the other clones do *not* receive that value. If you 
           want to send multiple copies of the same stream of values to 
           multiple destinations, like :func:`itertools.tee`, then you need to 
           find some other solution; this method does *not* do that. 
 
        Raises: 
          trio.ClosedResourceError: if you already closed this 
              `MemoryReceiveChannel` object. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">raise </span><span class="s1">trio.ClosedResourceError</span>
        <span class="s0">return </span><span class="s1">MemoryReceiveChannel._create(self._state)</span>

    <span class="s0">def </span><span class="s1">__enter__(self):</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">__exit__(self</span><span class="s0">, </span><span class="s1">exc_type</span><span class="s0">, </span><span class="s1">exc_val</span><span class="s0">, </span><span class="s1">exc_tb):</span>
        <span class="s1">self.close()</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">close(self):</span>
        <span class="s2">&quot;&quot;&quot;Close this receive channel object synchronously. 
 
        All channel objects have an asynchronous `~.AsyncResource.aclose` method. 
        Memory channels can also be closed synchronously. This has the same 
        effect on the channel and other tasks using it, but `close` is not a 
        trio checkpoint. This simplifies cleaning up in cancelled tasks. 
 
        Using ``with receive_channel:`` will close the channel object on 
        leaving the with block. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self._closed:</span>
            <span class="s0">return</span>
        <span class="s1">self._closed = </span><span class="s0">True</span>
        <span class="s0">for </span><span class="s1">task </span><span class="s0">in </span><span class="s1">self._tasks:</span>
            <span class="s1">trio.lowlevel.reschedule(task</span><span class="s0">, </span><span class="s1">Error(trio.ClosedResourceError()))</span>
            <span class="s0">del </span><span class="s1">self._state.receive_tasks[task]</span>
        <span class="s1">self._tasks.clear()</span>
        <span class="s1">self._state.open_receive_channels -= </span><span class="s4">1</span>
        <span class="s0">if </span><span class="s1">self._state.open_receive_channels == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">assert not </span><span class="s1">self._state.receive_tasks</span>
            <span class="s0">for </span><span class="s1">task </span><span class="s0">in </span><span class="s1">self._state.send_tasks:</span>
                <span class="s1">task.custom_sleep_data._tasks.remove(task)</span>
                <span class="s1">trio.lowlevel.reschedule(task</span><span class="s0">, </span><span class="s1">Error(trio.BrokenResourceError()))</span>
            <span class="s1">self._state.send_tasks.clear()</span>
            <span class="s1">self._state.data.clear()</span>

    <span class="s1">@enable_ki_protection</span>
    <span class="s0">async def </span><span class="s1">aclose(self):</span>
        <span class="s1">self.close()</span>
        <span class="s0">await </span><span class="s1">trio.lowlevel.checkpoint()</span>
</pre>
</body>
</html>