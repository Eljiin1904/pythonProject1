<html>
<head>
<title>others.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
others.py</font>
</center></td></tr></table>
<pre><span class="s0">#</span>
<span class="s0"># Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="s0"># &lt;see AUTHORS file&gt;</span>
<span class="s0">#</span>
<span class="s0"># This module is part of python-sqlparse and is released under</span>
<span class="s0"># the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>

<span class="s2">import </span><span class="s1">re</span>

<span class="s2">from </span><span class="s1">sqlparse </span><span class="s2">import </span><span class="s1">sql</span><span class="s2">, </span><span class="s1">tokens </span><span class="s2">as </span><span class="s1">T</span>
<span class="s2">from </span><span class="s1">sqlparse.utils </span><span class="s2">import </span><span class="s1">split_unquoted_newlines</span>


<span class="s2">class </span><span class="s1">StripCommentsFilter:</span>

    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">_process(tlist):</span>
        <span class="s2">def </span><span class="s1">get_next_comment():</span>
            <span class="s0"># TODO(andi) Comment types should be unified, see related issue38</span>
            <span class="s2">return </span><span class="s1">tlist.token_next_by(i=sql.Comment</span><span class="s2">, </span><span class="s1">t=T.Comment)</span>

        <span class="s2">def </span><span class="s1">_get_insert_token(token):</span>
            <span class="s3">&quot;&quot;&quot;Returns either a whitespace or the line breaks from token.&quot;&quot;&quot;</span>
            <span class="s0"># See issue484 why line breaks should be preserved.</span>
            <span class="s0"># Note: The actual value for a line break is replaced by \n</span>
            <span class="s0"># in SerializerUnicode which will be executed in the</span>
            <span class="s0"># postprocessing state.</span>
            <span class="s1">m = re.search(</span><span class="s4">r'((\r|\n)+) *$'</span><span class="s2">, </span><span class="s1">token.value)</span>
            <span class="s2">if </span><span class="s1">m </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">sql.Token(T.Whitespace.Newline</span><span class="s2">, </span><span class="s1">m.groups()[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">sql.Token(T.Whitespace</span><span class="s2">, </span><span class="s4">' '</span><span class="s1">)</span>

        <span class="s1">tidx</span><span class="s2">, </span><span class="s1">token = get_next_comment()</span>
        <span class="s2">while </span><span class="s1">token:</span>
            <span class="s1">pidx</span><span class="s2">, </span><span class="s1">prev_ = tlist.token_prev(tidx</span><span class="s2">, </span><span class="s1">skip_ws=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">nidx</span><span class="s2">, </span><span class="s1">next_ = tlist.token_next(tidx</span><span class="s2">, </span><span class="s1">skip_ws=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s0"># Replace by whitespace if prev and next exist and if they're not</span>
            <span class="s0"># whitespaces. This doesn't apply if prev or next is a parenthesis.</span>
            <span class="s2">if </span><span class="s1">(prev_ </span><span class="s2">is None or </span><span class="s1">next_ </span><span class="s2">is None</span>
                    <span class="s2">or </span><span class="s1">prev_.is_whitespace </span><span class="s2">or </span><span class="s1">prev_.match(T.Punctuation</span><span class="s2">, </span><span class="s4">'('</span><span class="s1">)</span>
                    <span class="s2">or </span><span class="s1">next_.is_whitespace </span><span class="s2">or </span><span class="s1">next_.match(T.Punctuation</span><span class="s2">, </span><span class="s4">')'</span><span class="s1">)):</span>
                <span class="s0"># Insert a whitespace to ensure the following SQL produces</span>
                <span class="s0"># a valid SQL (see #425).</span>
                <span class="s2">if </span><span class="s1">prev_ </span><span class="s2">is not None and not </span><span class="s1">prev_.match(T.Punctuation</span><span class="s2">, </span><span class="s4">'('</span><span class="s1">):</span>
                    <span class="s1">tlist.tokens.insert(tidx</span><span class="s2">, </span><span class="s1">_get_insert_token(token))</span>
                <span class="s1">tlist.tokens.remove(token)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">tlist.tokens[tidx] = _get_insert_token(token)</span>

            <span class="s1">tidx</span><span class="s2">, </span><span class="s1">token = get_next_comment()</span>

    <span class="s2">def </span><span class="s1">process(self</span><span class="s2">, </span><span class="s1">stmt):</span>
        <span class="s1">[self.process(sgroup) </span><span class="s2">for </span><span class="s1">sgroup </span><span class="s2">in </span><span class="s1">stmt.get_sublists()]</span>
        <span class="s1">StripCommentsFilter._process(stmt)</span>
        <span class="s2">return </span><span class="s1">stmt</span>


<span class="s2">class </span><span class="s1">StripWhitespaceFilter:</span>
    <span class="s2">def </span><span class="s1">_stripws(self</span><span class="s2">, </span><span class="s1">tlist):</span>
        <span class="s1">func_name = </span><span class="s4">'_stripws_{cls}'</span><span class="s1">.format(cls=type(tlist).__name__)</span>
        <span class="s1">func = getattr(self</span><span class="s2">, </span><span class="s1">func_name.lower()</span><span class="s2">, </span><span class="s1">self._stripws_default)</span>
        <span class="s1">func(tlist)</span>

    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">_stripws_default(tlist):</span>
        <span class="s1">last_was_ws = </span><span class="s2">False</span>
        <span class="s1">is_first_char = </span><span class="s2">True</span>
        <span class="s2">for </span><span class="s1">token </span><span class="s2">in </span><span class="s1">tlist.tokens:</span>
            <span class="s2">if </span><span class="s1">token.is_whitespace:</span>
                <span class="s1">token.value = </span><span class="s4">'' </span><span class="s2">if </span><span class="s1">last_was_ws </span><span class="s2">or </span><span class="s1">is_first_char </span><span class="s2">else </span><span class="s4">' '</span>
            <span class="s1">last_was_ws = token.is_whitespace</span>
            <span class="s1">is_first_char = </span><span class="s2">False</span>

    <span class="s2">def </span><span class="s1">_stripws_identifierlist(self</span><span class="s2">, </span><span class="s1">tlist):</span>
        <span class="s0"># Removes newlines before commas, see issue140</span>
        <span class="s1">last_nl = </span><span class="s2">None</span>
        <span class="s2">for </span><span class="s1">token </span><span class="s2">in </span><span class="s1">list(tlist.tokens):</span>
            <span class="s2">if </span><span class="s1">last_nl </span><span class="s2">and </span><span class="s1">token.ttype </span><span class="s2">is </span><span class="s1">T.Punctuation </span><span class="s2">and </span><span class="s1">token.value == </span><span class="s4">','</span><span class="s1">:</span>
                <span class="s1">tlist.tokens.remove(last_nl)</span>
            <span class="s1">last_nl = token </span><span class="s2">if </span><span class="s1">token.is_whitespace </span><span class="s2">else None</span>

            <span class="s0"># next_ = tlist.token_next(token, skip_ws=False)</span>
            <span class="s0"># if (next_ and not next_.is_whitespace and</span>
            <span class="s0">#             token.ttype is T.Punctuation and token.value == ','):</span>
            <span class="s0">#     tlist.insert_after(token, sql.Token(T.Whitespace, ' '))</span>
        <span class="s2">return </span><span class="s1">self._stripws_default(tlist)</span>

    <span class="s2">def </span><span class="s1">_stripws_parenthesis(self</span><span class="s2">, </span><span class="s1">tlist):</span>
        <span class="s2">while </span><span class="s1">tlist.tokens[</span><span class="s5">1</span><span class="s1">].is_whitespace:</span>
            <span class="s1">tlist.tokens.pop(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">while </span><span class="s1">tlist.tokens[-</span><span class="s5">2</span><span class="s1">].is_whitespace:</span>
            <span class="s1">tlist.tokens.pop(-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">self._stripws_default(tlist)</span>

    <span class="s2">def </span><span class="s1">process(self</span><span class="s2">, </span><span class="s1">stmt</span><span class="s2">, </span><span class="s1">depth=</span><span class="s5">0</span><span class="s1">):</span>
        <span class="s1">[self.process(sgroup</span><span class="s2">, </span><span class="s1">depth + </span><span class="s5">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">sgroup </span><span class="s2">in </span><span class="s1">stmt.get_sublists()]</span>
        <span class="s1">self._stripws(stmt)</span>
        <span class="s2">if </span><span class="s1">depth == </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">stmt.tokens </span><span class="s2">and </span><span class="s1">stmt.tokens[-</span><span class="s5">1</span><span class="s1">].is_whitespace:</span>
            <span class="s1">stmt.tokens.pop(-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">stmt</span>


<span class="s2">class </span><span class="s1">SpacesAroundOperatorsFilter:</span>
    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">_process(tlist):</span>

        <span class="s1">ttypes = (T.Operator</span><span class="s2">, </span><span class="s1">T.Comparison)</span>
        <span class="s1">tidx</span><span class="s2">, </span><span class="s1">token = tlist.token_next_by(t=ttypes)</span>
        <span class="s2">while </span><span class="s1">token:</span>
            <span class="s1">nidx</span><span class="s2">, </span><span class="s1">next_ = tlist.token_next(tidx</span><span class="s2">, </span><span class="s1">skip_ws=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">next_ </span><span class="s2">and </span><span class="s1">next_.ttype != T.Whitespace:</span>
                <span class="s1">tlist.insert_after(tidx</span><span class="s2">, </span><span class="s1">sql.Token(T.Whitespace</span><span class="s2">, </span><span class="s4">' '</span><span class="s1">))</span>

            <span class="s1">pidx</span><span class="s2">, </span><span class="s1">prev_ = tlist.token_prev(tidx</span><span class="s2">, </span><span class="s1">skip_ws=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">prev_ </span><span class="s2">and </span><span class="s1">prev_.ttype != T.Whitespace:</span>
                <span class="s1">tlist.insert_before(tidx</span><span class="s2">, </span><span class="s1">sql.Token(T.Whitespace</span><span class="s2">, </span><span class="s4">' '</span><span class="s1">))</span>
                <span class="s1">tidx += </span><span class="s5">1  </span><span class="s0"># has to shift since token inserted before it</span>

            <span class="s0"># assert tlist.token_index(token) == tidx</span>
            <span class="s1">tidx</span><span class="s2">, </span><span class="s1">token = tlist.token_next_by(t=ttypes</span><span class="s2">, </span><span class="s1">idx=tidx)</span>

    <span class="s2">def </span><span class="s1">process(self</span><span class="s2">, </span><span class="s1">stmt):</span>
        <span class="s1">[self.process(sgroup) </span><span class="s2">for </span><span class="s1">sgroup </span><span class="s2">in </span><span class="s1">stmt.get_sublists()]</span>
        <span class="s1">SpacesAroundOperatorsFilter._process(stmt)</span>
        <span class="s2">return </span><span class="s1">stmt</span>


<span class="s0"># ---------------------------</span>
<span class="s0"># postprocess</span>

<span class="s2">class </span><span class="s1">SerializerUnicode:</span>
    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">process(stmt):</span>
        <span class="s1">lines = split_unquoted_newlines(stmt)</span>
        <span class="s2">return </span><span class="s4">'</span><span class="s2">\n</span><span class="s4">'</span><span class="s1">.join(line.rstrip() </span><span class="s2">for </span><span class="s1">line </span><span class="s2">in </span><span class="s1">lines)</span>
</pre>
</body>
</html>