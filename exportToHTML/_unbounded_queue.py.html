<html>
<head>
<title>_unbounded_queue.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_unbounded_queue.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">attr</span>

<span class="s0">from </span><span class="s1">.. </span><span class="s0">import </span><span class="s1">_core</span>
<span class="s0">from </span><span class="s1">.._deprecate </span><span class="s0">import </span><span class="s1">deprecated</span>
<span class="s0">from </span><span class="s1">.._util </span><span class="s0">import </span><span class="s1">Final</span>


<span class="s1">@attr.s(frozen=</span><span class="s0">True</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">_UnboundedQueueStats:</span>
    <span class="s1">qsize = attr.ib()</span>
    <span class="s1">tasks_waiting = attr.ib()</span>


<span class="s0">class </span><span class="s1">UnboundedQueue(metaclass=Final):</span>
    <span class="s2">&quot;&quot;&quot;An unbounded queue suitable for certain unusual forms of inter-task 
    communication. 
 
    This class is designed for use as a queue in cases where the producer for 
    some reason cannot be subjected to back-pressure, i.e., :meth:`put_nowait` 
    has to always succeed. In order to prevent the queue backlog from actually 
    growing without bound, the consumer API is modified to dequeue items in 
    &quot;batches&quot;. If a consumer task processes each batch without yielding, then 
    this helps achieve (but does not guarantee) an effective bound on the 
    queue's memory use, at the cost of potentially increasing system latencies 
    in general. You should generally prefer to use a memory channel 
    instead if you can. 
 
    Currently each batch completely empties the queue, but `this may change in 
    the future &lt;https://github.com/python-trio/trio/issues/51&gt;`__. 
 
    A :class:`UnboundedQueue` object can be used as an asynchronous iterator, 
    where each iteration returns a new batch of items. I.e., these two loops 
    are equivalent:: 
 
       async for batch in queue: 
           ... 
 
       while True: 
           obj = await queue.get_batch() 
           ... 
 
    &quot;&quot;&quot;</span>

    <span class="s1">@deprecated(</span>
        <span class="s3">&quot;0.9.0&quot;</span><span class="s0">,</span>
        <span class="s1">issue=</span><span class="s4">497</span><span class="s0">,</span>
        <span class="s1">thing=</span><span class="s3">&quot;trio.lowlevel.UnboundedQueue&quot;</span><span class="s0">,</span>
        <span class="s1">instead=</span><span class="s3">&quot;trio.open_memory_channel(math.inf)&quot;</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self._lot = _core.ParkingLot()</span>
        <span class="s1">self._data = []</span>
        <span class="s5"># used to allow handoff from put to the first task in the lot</span>
        <span class="s1">self._can_get = </span><span class="s0">False</span>

    <span class="s0">def </span><span class="s1">__repr__(self):</span>
        <span class="s0">return </span><span class="s3">&quot;&lt;UnboundedQueue holding {} items&gt;&quot;</span><span class="s1">.format(len(self._data))</span>

    <span class="s0">def </span><span class="s1">qsize(self):</span>
        <span class="s2">&quot;&quot;&quot;Returns the number of items currently in the queue.&quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">len(self._data)</span>

    <span class="s0">def </span><span class="s1">empty(self):</span>
        <span class="s2">&quot;&quot;&quot;Returns True if the queue is empty, False otherwise. 
 
        There is some subtlety to interpreting this method's return value: see 
        `issue #63 &lt;https://github.com/python-trio/trio/issues/63&gt;`__. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">return not </span><span class="s1">self._data</span>

    <span class="s1">@_core.enable_ki_protection</span>
    <span class="s0">def </span><span class="s1">put_nowait(self</span><span class="s0">, </span><span class="s1">obj):</span>
        <span class="s2">&quot;&quot;&quot;Put an object into the queue, without blocking. 
 
        This always succeeds, because the queue is unbounded. We don't provide 
        a blocking ``put`` method, because it would never need to block. 
 
        Args: 
          obj (object): The object to enqueue. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if not </span><span class="s1">self._data:</span>
            <span class="s0">assert not </span><span class="s1">self._can_get</span>
            <span class="s0">if </span><span class="s1">self._lot:</span>
                <span class="s1">self._lot.unpark(count=</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self._can_get = </span><span class="s0">True</span>
        <span class="s1">self._data.append(obj)</span>

    <span class="s0">def </span><span class="s1">_get_batch_protected(self):</span>
        <span class="s1">data = self._data.copy()</span>
        <span class="s1">self._data.clear()</span>
        <span class="s1">self._can_get = </span><span class="s0">False</span>
        <span class="s0">return </span><span class="s1">data</span>

    <span class="s0">def </span><span class="s1">get_batch_nowait(self):</span>
        <span class="s2">&quot;&quot;&quot;Attempt to get the next batch from the queue, without blocking. 
 
        Returns: 
          list: A list of dequeued items, in order. On a successful call this 
              list is always non-empty; if it would be empty we raise 
              :exc:`~trio.WouldBlock` instead. 
 
        Raises: 
          ~trio.WouldBlock: if the queue is empty. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if not </span><span class="s1">self._can_get:</span>
            <span class="s0">raise </span><span class="s1">_core.WouldBlock</span>
        <span class="s0">return </span><span class="s1">self._get_batch_protected()</span>

    <span class="s0">async def </span><span class="s1">get_batch(self):</span>
        <span class="s2">&quot;&quot;&quot;Get the next batch from the queue, blocking as necessary. 
 
        Returns: 
          list: A list of dequeued items, in order. This list is always 
              non-empty. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">await </span><span class="s1">_core.checkpoint_if_cancelled()</span>
        <span class="s0">if not </span><span class="s1">self._can_get:</span>
            <span class="s0">await </span><span class="s1">self._lot.park()</span>
            <span class="s0">return </span><span class="s1">self._get_batch_protected()</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">self._get_batch_protected()</span>
            <span class="s0">finally</span><span class="s1">:</span>
                <span class="s0">await </span><span class="s1">_core.cancel_shielded_checkpoint()</span>

    <span class="s0">def </span><span class="s1">statistics(self):</span>
        <span class="s2">&quot;&quot;&quot;Return an object containing debugging information. 
 
        Currently the following fields are defined: 
 
        * ``qsize``: The number of items currently in the queue. 
        * ``tasks_waiting``: The number of tasks blocked on this queue's 
          :meth:`get_batch` method. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">_UnboundedQueueStats(</span>
            <span class="s1">qsize=len(self._data)</span><span class="s0">, </span><span class="s1">tasks_waiting=self._lot.statistics().tasks_waiting</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">__aiter__(self):</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">async def </span><span class="s1">__anext__(self):</span>
        <span class="s0">return await </span><span class="s1">self.get_batch()</span>
</pre>
</body>
</html>