<html>
<head>
<title>_entry_queue.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_entry_queue.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">collections </span><span class="s0">import </span><span class="s1">deque</span>
<span class="s0">import </span><span class="s1">threading</span>

<span class="s0">import </span><span class="s1">attr</span>

<span class="s0">from </span><span class="s1">.. </span><span class="s0">import </span><span class="s1">_core</span>
<span class="s0">from </span><span class="s1">.._util </span><span class="s0">import </span><span class="s1">NoPublicConstructor</span>
<span class="s0">from </span><span class="s1">._wakeup_socketpair </span><span class="s0">import </span><span class="s1">WakeupSocketpair</span>


<span class="s1">@attr.s(slots=</span><span class="s0">True</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">EntryQueue:</span>
    <span class="s2"># This used to use a queue.Queue. but that was broken, because Queues are</span>
    <span class="s2"># implemented in Python, and not reentrant -- so it was thread-safe, but</span>
    <span class="s2"># not signal-safe. deque is implemented in C, so each operation is atomic</span>
    <span class="s2"># WRT threads (and this is guaranteed in the docs), AND each operation is</span>
    <span class="s2"># atomic WRT signal delivery (signal handlers can run on either side, but</span>
    <span class="s2"># not *during* a deque operation). dict makes similar guarantees - and on</span>
    <span class="s2"># CPython 3.6 and PyPy, it's even ordered!</span>
    <span class="s1">queue = attr.ib(factory=deque)</span>
    <span class="s1">idempotent_queue = attr.ib(factory=dict)</span>

    <span class="s1">wakeup = attr.ib(factory=WakeupSocketpair)</span>
    <span class="s1">done = attr.ib(default=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s2"># Must be a reentrant lock, because it's acquired from signal handlers.</span>
    <span class="s2"># RLock is signal-safe as of cpython 3.2. NB that this does mean that the</span>
    <span class="s2"># lock is effectively *disabled* when we enter from signal context. The</span>
    <span class="s2"># way we use the lock this is OK though, because when</span>
    <span class="s2"># run_sync_soon is called from a signal it's atomic WRT the</span>
    <span class="s2"># main thread -- it just might happen at some inconvenient place. But if</span>
    <span class="s2"># you look at the one place where the main thread holds the lock, it's</span>
    <span class="s2"># just to make 1 assignment, so that's atomic WRT a signal anyway.</span>
    <span class="s1">lock = attr.ib(factory=threading.RLock)</span>

    <span class="s0">async def </span><span class="s1">task(self):</span>
        <span class="s0">assert </span><span class="s1">_core.currently_ki_protected()</span>
        <span class="s2"># RLock has two implementations: a signal-safe version in _thread, and</span>
        <span class="s2"># and signal-UNsafe version in threading. We need the signal safe</span>
        <span class="s2"># version. Python 3.2 and later should always use this anyway, but,</span>
        <span class="s2"># since the symptoms if this goes wrong are just &quot;weird rare</span>
        <span class="s2"># deadlocks&quot;, then let's make a little check.</span>
        <span class="s2"># See:</span>
        <span class="s2">#     https://bugs.python.org/issue13697#msg237140</span>
        <span class="s0">assert </span><span class="s1">self.lock.__class__.__module__ == </span><span class="s3">&quot;_thread&quot;</span>

        <span class="s0">def </span><span class="s1">run_cb(job):</span>
            <span class="s2"># We run this with KI protection enabled; it's the callback's</span>
            <span class="s2"># job to disable it if it wants it disabled. Exceptions are</span>
            <span class="s2"># treated like system task exceptions (i.e., converted into</span>
            <span class="s2"># TrioInternalError and cause everything to shut down).</span>
            <span class="s1">sync_fn</span><span class="s0">, </span><span class="s1">args = job</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">sync_fn(*args)</span>
            <span class="s0">except </span><span class="s1">BaseException </span><span class="s0">as </span><span class="s1">exc:</span>

                <span class="s0">async def </span><span class="s1">kill_everything(exc):</span>
                    <span class="s0">raise </span><span class="s1">exc</span>

                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">_core.spawn_system_task(kill_everything</span><span class="s0">, </span><span class="s1">exc)</span>
                <span class="s0">except </span><span class="s1">RuntimeError:</span>
                    <span class="s2"># We're quite late in the shutdown process and the</span>
                    <span class="s2"># system nursery is already closed.</span>
                    <span class="s2"># TODO(2020-06): this is a gross hack and should</span>
                    <span class="s2"># be fixed soon when we address #1607.</span>
                    <span class="s1">_core.current_task().parent_nursery.start_soon(kill_everything</span><span class="s0">, </span><span class="s1">exc)</span>

            <span class="s0">return True</span>

        <span class="s2"># This has to be carefully written to be safe in the face of new items</span>
        <span class="s2"># being queued while we iterate, and to do a bounded amount of work on</span>
        <span class="s2"># each pass:</span>
        <span class="s0">def </span><span class="s1">run_all_bounded():</span>
            <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range(len(self.queue)):</span>
                <span class="s1">run_cb(self.queue.popleft())</span>
            <span class="s0">for </span><span class="s1">job </span><span class="s0">in </span><span class="s1">list(self.idempotent_queue):</span>
                <span class="s0">del </span><span class="s1">self.idempotent_queue[job]</span>
                <span class="s1">run_cb(job)</span>

        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">while True</span><span class="s1">:</span>
                <span class="s1">run_all_bounded()</span>
                <span class="s0">if not </span><span class="s1">self.queue </span><span class="s0">and not </span><span class="s1">self.idempotent_queue:</span>
                    <span class="s0">await </span><span class="s1">self.wakeup.wait_woken()</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s0">await </span><span class="s1">_core.checkpoint()</span>
        <span class="s0">except </span><span class="s1">_core.Cancelled:</span>
            <span class="s2"># Keep the work done with this lock held as minimal as possible,</span>
            <span class="s2"># because it doesn't protect us against concurrent signal delivery</span>
            <span class="s2"># (see the comment above). Notice that this code would still be</span>
            <span class="s2"># correct if written like:</span>
            <span class="s2">#   self.done = True</span>
            <span class="s2">#   with self.lock:</span>
            <span class="s2">#       pass</span>
            <span class="s2"># because all we want is to force run_sync_soon</span>
            <span class="s2"># to either be completely before or completely after the write to</span>
            <span class="s2"># done. That's why we don't need the lock to protect</span>
            <span class="s2"># against signal handlers.</span>
            <span class="s0">with </span><span class="s1">self.lock:</span>
                <span class="s1">self.done = </span><span class="s0">True</span>
            <span class="s2"># No more jobs will be submitted, so just clear out any residual</span>
            <span class="s2"># ones:</span>
            <span class="s1">run_all_bounded()</span>
            <span class="s0">assert not </span><span class="s1">self.queue</span>
            <span class="s0">assert not </span><span class="s1">self.idempotent_queue</span>

    <span class="s0">def </span><span class="s1">close(self):</span>
        <span class="s1">self.wakeup.close()</span>

    <span class="s0">def </span><span class="s1">size(self):</span>
        <span class="s0">return </span><span class="s1">len(self.queue) + len(self.idempotent_queue)</span>

    <span class="s0">def </span><span class="s1">run_sync_soon(self</span><span class="s0">, </span><span class="s1">sync_fn</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">idempotent=</span><span class="s0">False</span><span class="s1">):</span>
        <span class="s0">with </span><span class="s1">self.lock:</span>
            <span class="s0">if </span><span class="s1">self.done:</span>
                <span class="s0">raise </span><span class="s1">_core.RunFinishedError(</span><span class="s3">&quot;run() has exited&quot;</span><span class="s1">)</span>
            <span class="s2"># We have to hold the lock all the way through here, because</span>
            <span class="s2"># otherwise the main thread might exit *while* we're doing these</span>
            <span class="s2"># calls, and then our queue item might not be processed, or the</span>
            <span class="s2"># wakeup call might trigger an OSError b/c the IO manager has</span>
            <span class="s2"># already been shut down.</span>
            <span class="s0">if </span><span class="s1">idempotent:</span>
                <span class="s1">self.idempotent_queue[(sync_fn</span><span class="s0">, </span><span class="s1">args)] = </span><span class="s0">None</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self.queue.append((sync_fn</span><span class="s0">, </span><span class="s1">args))</span>
            <span class="s1">self.wakeup.wakeup_thread_and_signal_safe()</span>


<span class="s1">@attr.s(eq=</span><span class="s0">False, </span><span class="s1">hash=</span><span class="s0">False, </span><span class="s1">slots=</span><span class="s0">True</span><span class="s1">)</span>
<span class="s0">class </span><span class="s1">TrioToken(metaclass=NoPublicConstructor):</span>
    <span class="s4">&quot;&quot;&quot;An opaque object representing a single call to :func:`trio.run`. 
 
    It has no public constructor; instead, see :func:`current_trio_token`. 
 
    This object has two uses: 
 
    1. It lets you re-enter the Trio run loop from external threads or signal 
       handlers. This is the low-level primitive that :func:`trio.to_thread` 
       and `trio.from_thread` use to communicate with worker threads, that 
       `trio.open_signal_receiver` uses to receive notifications about 
       signals, and so forth. 
 
    2. Each call to :func:`trio.run` has exactly one associated 
       :class:`TrioToken` object, so you can use it to identify a particular 
       call. 
 
    &quot;&quot;&quot;</span>

    <span class="s1">_reentry_queue = attr.ib()</span>

    <span class="s0">def </span><span class="s1">run_sync_soon(self</span><span class="s0">, </span><span class="s1">sync_fn</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">idempotent=</span><span class="s0">False</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot;Schedule a call to ``sync_fn(*args)`` to occur in the context of a 
        Trio task. 
 
        This is safe to call from the main thread, from other threads, and 
        from signal handlers. This is the fundamental primitive used to 
        re-enter the Trio run loop from outside of it. 
 
        The call will happen &quot;soon&quot;, but there's no guarantee about exactly 
        when, and no mechanism provided for finding out when it's happened. 
        If you need this, you'll have to build your own. 
 
        The call is effectively run as part of a system task (see 
        :func:`~trio.lowlevel.spawn_system_task`). In particular this means 
        that: 
 
        * :exc:`KeyboardInterrupt` protection is *enabled* by default; if 
          you want ``sync_fn`` to be interruptible by control-C, then you 
          need to use :func:`~trio.lowlevel.disable_ki_protection` 
          explicitly. 
 
        * If ``sync_fn`` raises an exception, then it's converted into a 
          :exc:`~trio.TrioInternalError` and *all* tasks are cancelled. You 
          should be careful that ``sync_fn`` doesn't crash. 
 
        All calls with ``idempotent=False`` are processed in strict 
        first-in first-out order. 
 
        If ``idempotent=True``, then ``sync_fn`` and ``args`` must be 
        hashable, and Trio will make a best-effort attempt to discard any 
        call submission which is equal to an already-pending call. Trio 
        will process these in first-in first-out order. 
 
        Any ordering guarantees apply separately to ``idempotent=False`` 
        and ``idempotent=True`` calls; there's no rule for how calls in the 
        different categories are ordered with respect to each other. 
 
        :raises trio.RunFinishedError: 
              if the associated call to :func:`trio.run` 
              has already exited. (Any call that *doesn't* raise this error 
              is guaranteed to be fully processed before :func:`trio.run` 
              exits.) 
 
        &quot;&quot;&quot;</span>
        <span class="s1">self._reentry_queue.run_sync_soon(sync_fn</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">idempotent=idempotent)</span>
</pre>
</body>
</html>