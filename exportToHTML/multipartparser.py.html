<html>
<head>
<title>multipartparser.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
.s6 { color: #a5c261;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
multipartparser.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Multi-part parsing for file uploads. 
 
Exposes one class, ``MultiPartParser``, which feeds chunks of uploaded data to 
file upload handlers for processing. 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">base64</span>
<span class="s2">import </span><span class="s1">binascii</span>
<span class="s2">import </span><span class="s1">cgi</span>
<span class="s2">import </span><span class="s1">collections</span>
<span class="s2">import </span><span class="s1">html</span>
<span class="s2">from </span><span class="s1">urllib.parse </span><span class="s2">import </span><span class="s1">unquote</span>

<span class="s2">from </span><span class="s1">django.conf </span><span class="s2">import </span><span class="s1">settings</span>
<span class="s2">from </span><span class="s1">django.core.exceptions </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">RequestDataTooBig</span><span class="s2">, </span><span class="s1">SuspiciousMultipartForm</span><span class="s2">, </span><span class="s1">TooManyFieldsSent</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">django.core.files.uploadhandler </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">SkipFile</span><span class="s2">, </span><span class="s1">StopFutureHandlers</span><span class="s2">, </span><span class="s1">StopUpload</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">django.utils.datastructures </span><span class="s2">import </span><span class="s1">MultiValueDict</span>
<span class="s2">from </span><span class="s1">django.utils.encoding </span><span class="s2">import </span><span class="s1">force_str</span>

<span class="s1">__all__ = (</span><span class="s3">'MultiPartParser'</span><span class="s2">, </span><span class="s3">'MultiPartParserError'</span><span class="s2">, </span><span class="s3">'InputStreamExhausted'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">MultiPartParserError(Exception):</span>
    <span class="s2">pass</span>


<span class="s2">class </span><span class="s1">InputStreamExhausted(Exception):</span>
    <span class="s0">&quot;&quot;&quot; 
    No more reads are allowed from this device. 
    &quot;&quot;&quot;</span>
    <span class="s2">pass</span>


<span class="s1">RAW = </span><span class="s3">&quot;raw&quot;</span>
<span class="s1">FILE = </span><span class="s3">&quot;file&quot;</span>
<span class="s1">FIELD = </span><span class="s3">&quot;field&quot;</span>


<span class="s2">class </span><span class="s1">MultiPartParser:</span>
    <span class="s0">&quot;&quot;&quot; 
    A rfc2388 multipart/form-data parser. 
 
    ``MultiValueDict.parse()`` reads the input stream in ``chunk_size`` chunks 
    and returns a tuple of ``(MultiValueDict(POST), MultiValueDict(FILES))``. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">META</span><span class="s2">, </span><span class="s1">input_data</span><span class="s2">, </span><span class="s1">upload_handlers</span><span class="s2">, </span><span class="s1">encoding=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Initialize the MultiPartParser object. 
 
        :META: 
            The standard ``META`` dictionary in Django request objects. 
        :input_data: 
            The raw post data, as a file-like object. 
        :upload_handlers: 
            A list of UploadHandler instances that perform operations on the 
            uploaded data. 
        :encoding: 
            The encoding with which to treat the incoming data. 
        &quot;&quot;&quot;</span>
        <span class="s4"># Content-Type should contain multipart and the boundary information.</span>
        <span class="s1">content_type = META.get(</span><span class="s3">'CONTENT_TYPE'</span><span class="s2">, </span><span class="s3">''</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">content_type.startswith(</span><span class="s3">'multipart/'</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">MultiPartParserError(</span><span class="s3">'Invalid Content-Type: %s' </span><span class="s1">% content_type)</span>

        <span class="s4"># Parse the header to get the boundary to split the parts.</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">ctypes</span><span class="s2">, </span><span class="s1">opts = parse_header(content_type.encode(</span><span class="s3">'ascii'</span><span class="s1">))</span>
        <span class="s2">except </span><span class="s1">UnicodeEncodeError:</span>
            <span class="s2">raise </span><span class="s1">MultiPartParserError(</span><span class="s3">'Invalid non-ASCII Content-Type in multipart: %s' </span><span class="s1">% force_str(content_type))</span>
        <span class="s1">boundary = opts.get(</span><span class="s3">'boundary'</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">boundary </span><span class="s2">or not </span><span class="s1">cgi.valid_boundary(boundary):</span>
            <span class="s2">raise </span><span class="s1">MultiPartParserError(</span><span class="s3">'Invalid boundary in multipart: %s' </span><span class="s1">% force_str(boundary))</span>

        <span class="s4"># Content-Length should contain the length of the body we are about</span>
        <span class="s4"># to receive.</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">content_length = int(META.get(</span><span class="s3">'CONTENT_LENGTH'</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
        <span class="s2">except </span><span class="s1">(ValueError</span><span class="s2">, </span><span class="s1">TypeError):</span>
            <span class="s1">content_length = </span><span class="s5">0</span>

        <span class="s2">if </span><span class="s1">content_length &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># This means we shouldn't continue...raise an error.</span>
            <span class="s2">raise </span><span class="s1">MultiPartParserError(</span><span class="s3">&quot;Invalid content length: %r&quot; </span><span class="s1">% content_length)</span>

        <span class="s2">if </span><span class="s1">isinstance(boundary</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">boundary = boundary.encode(</span><span class="s3">'ascii'</span><span class="s1">)</span>
        <span class="s1">self._boundary = boundary</span>
        <span class="s1">self._input_data = input_data</span>

        <span class="s4"># For compatibility with low-level network APIs (with 32-bit integers),</span>
        <span class="s4"># the chunk size should be &lt; 2^31, but still divisible by 4.</span>
        <span class="s1">possible_sizes = [x.chunk_size </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">upload_handlers </span><span class="s2">if </span><span class="s1">x.chunk_size]</span>
        <span class="s1">self._chunk_size = min([</span><span class="s5">2 </span><span class="s1">** </span><span class="s5">31 </span><span class="s1">- </span><span class="s5">4</span><span class="s1">] + possible_sizes)</span>

        <span class="s1">self._meta = META</span>
        <span class="s1">self._encoding = encoding </span><span class="s2">or </span><span class="s1">settings.DEFAULT_CHARSET</span>
        <span class="s1">self._content_length = content_length</span>
        <span class="s1">self._upload_handlers = upload_handlers</span>

    <span class="s2">def </span><span class="s1">parse(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Parse the POST data and break it into a FILES MultiValueDict and a POST 
        MultiValueDict. 
 
        Return a tuple containing the POST and FILES dictionary, respectively. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">django.http </span><span class="s2">import </span><span class="s1">QueryDict</span>

        <span class="s1">encoding = self._encoding</span>
        <span class="s1">handlers = self._upload_handlers</span>

        <span class="s4"># HTTP spec says that Content-Length &gt;= 0 is valid</span>
        <span class="s4"># handling content-length == 0 before continuing</span>
        <span class="s2">if </span><span class="s1">self._content_length == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">QueryDict(encoding=self._encoding)</span><span class="s2">, </span><span class="s1">MultiValueDict()</span>

        <span class="s4"># See if any of the handlers take care of the parsing.</span>
        <span class="s4"># This allows overriding everything if need be.</span>
        <span class="s2">for </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">handlers:</span>
            <span class="s1">result = handler.handle_raw_input(</span>
                <span class="s1">self._input_data</span><span class="s2">,</span>
                <span class="s1">self._meta</span><span class="s2">,</span>
                <span class="s1">self._content_length</span><span class="s2">,</span>
                <span class="s1">self._boundary</span><span class="s2">,</span>
                <span class="s1">encoding</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s4"># Check to see if it was handled</span>
            <span class="s2">if </span><span class="s1">result </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">result[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">result[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s4"># Create the data structures to be used later.</span>
        <span class="s1">self._post = QueryDict(mutable=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">self._files = MultiValueDict()</span>

        <span class="s4"># Instantiate the parser and stream:</span>
        <span class="s1">stream = LazyStream(ChunkIter(self._input_data</span><span class="s2">, </span><span class="s1">self._chunk_size))</span>

        <span class="s4"># Whether or not to signal a file-completion at the beginning of the loop.</span>
        <span class="s1">old_field_name = </span><span class="s2">None</span>
        <span class="s1">counters = [</span><span class="s5">0</span><span class="s1">] * len(handlers)</span>

        <span class="s4"># Number of bytes that have been read.</span>
        <span class="s1">num_bytes_read = </span><span class="s5">0</span>
        <span class="s4"># To count the number of keys in the request.</span>
        <span class="s1">num_post_keys = </span><span class="s5">0</span>
        <span class="s4"># To limit the amount of data read from the request.</span>
        <span class="s1">read_size = </span><span class="s2">None</span>
        <span class="s4"># Whether a file upload is finished.</span>
        <span class="s1">uploaded_file = </span><span class="s2">True</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">item_type</span><span class="s2">, </span><span class="s1">meta_data</span><span class="s2">, </span><span class="s1">field_stream </span><span class="s2">in </span><span class="s1">Parser(stream</span><span class="s2">, </span><span class="s1">self._boundary):</span>
                <span class="s2">if </span><span class="s1">old_field_name:</span>
                    <span class="s4"># We run this at the beginning of the next loop</span>
                    <span class="s4"># since we cannot be sure a file is complete until</span>
                    <span class="s4"># we hit the next boundary/part of the multipart content.</span>
                    <span class="s1">self.handle_file_complete(old_field_name</span><span class="s2">, </span><span class="s1">counters)</span>
                    <span class="s1">old_field_name = </span><span class="s2">None</span>
                    <span class="s1">uploaded_file = </span><span class="s2">True</span>

                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">disposition = meta_data[</span><span class="s3">'content-disposition'</span><span class="s1">][</span><span class="s5">1</span><span class="s1">]</span>
                    <span class="s1">field_name = disposition[</span><span class="s3">'name'</span><span class="s1">].strip()</span>
                <span class="s2">except </span><span class="s1">(KeyError</span><span class="s2">, </span><span class="s1">IndexError</span><span class="s2">, </span><span class="s1">AttributeError):</span>
                    <span class="s2">continue</span>

                <span class="s1">transfer_encoding = meta_data.get(</span><span class="s3">'content-transfer-encoding'</span><span class="s1">)</span>
                <span class="s2">if </span><span class="s1">transfer_encoding </span><span class="s2">is not None</span><span class="s1">:</span>
                    <span class="s1">transfer_encoding = transfer_encoding[</span><span class="s5">0</span><span class="s1">].strip()</span>
                <span class="s1">field_name = force_str(field_name</span><span class="s2">, </span><span class="s1">encoding</span><span class="s2">, </span><span class="s1">errors=</span><span class="s3">'replace'</span><span class="s1">)</span>

                <span class="s2">if </span><span class="s1">item_type == FIELD:</span>
                    <span class="s4"># Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.</span>
                    <span class="s1">num_post_keys += </span><span class="s5">1</span>
                    <span class="s2">if </span><span class="s1">(settings.DATA_UPLOAD_MAX_NUMBER_FIELDS </span><span class="s2">is not None and</span>
                            <span class="s1">settings.DATA_UPLOAD_MAX_NUMBER_FIELDS &lt; num_post_keys):</span>
                        <span class="s2">raise </span><span class="s1">TooManyFieldsSent(</span>
                            <span class="s3">'The number of GET/POST parameters exceeded '</span>
                            <span class="s3">'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'</span>
                        <span class="s1">)</span>

                    <span class="s4"># Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.</span>
                    <span class="s2">if </span><span class="s1">settings.DATA_UPLOAD_MAX_MEMORY_SIZE </span><span class="s2">is not None</span><span class="s1">:</span>
                        <span class="s1">read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read</span>

                    <span class="s4"># This is a post field, we can just set it in the post</span>
                    <span class="s2">if </span><span class="s1">transfer_encoding == </span><span class="s3">'base64'</span><span class="s1">:</span>
                        <span class="s1">raw_data = field_stream.read(size=read_size)</span>
                        <span class="s1">num_bytes_read += len(raw_data)</span>
                        <span class="s2">try</span><span class="s1">:</span>
                            <span class="s1">data = base64.b64decode(raw_data)</span>
                        <span class="s2">except </span><span class="s1">binascii.Error:</span>
                            <span class="s1">data = raw_data</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">data = field_stream.read(size=read_size)</span>
                        <span class="s1">num_bytes_read += len(data)</span>

                    <span class="s4"># Add two here to make the check consistent with the</span>
                    <span class="s4"># x-www-form-urlencoded check that includes '&amp;='.</span>
                    <span class="s1">num_bytes_read += len(field_name) + </span><span class="s5">2</span>
                    <span class="s2">if </span><span class="s1">(settings.DATA_UPLOAD_MAX_MEMORY_SIZE </span><span class="s2">is not None and</span>
                            <span class="s1">num_bytes_read &gt; settings.DATA_UPLOAD_MAX_MEMORY_SIZE):</span>
                        <span class="s2">raise </span><span class="s1">RequestDataTooBig(</span><span class="s3">'Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.'</span><span class="s1">)</span>

                    <span class="s1">self._post.appendlist(field_name</span><span class="s2">, </span><span class="s1">force_str(data</span><span class="s2">, </span><span class="s1">encoding</span><span class="s2">, </span><span class="s1">errors=</span><span class="s3">'replace'</span><span class="s1">))</span>
                <span class="s2">elif </span><span class="s1">item_type == FILE:</span>
                    <span class="s4"># This is a file, use the handler...</span>
                    <span class="s1">file_name = disposition.get(</span><span class="s3">'filename'</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">file_name:</span>
                        <span class="s1">file_name = force_str(file_name</span><span class="s2">, </span><span class="s1">encoding</span><span class="s2">, </span><span class="s1">errors=</span><span class="s3">'replace'</span><span class="s1">)</span>
                        <span class="s1">file_name = self.sanitize_file_name(file_name)</span>
                    <span class="s2">if not </span><span class="s1">file_name:</span>
                        <span class="s2">continue</span>

                    <span class="s1">content_type</span><span class="s2">, </span><span class="s1">content_type_extra = meta_data.get(</span><span class="s3">'content-type'</span><span class="s2">, </span><span class="s1">(</span><span class="s3">''</span><span class="s2">, </span><span class="s1">{}))</span>
                    <span class="s1">content_type = content_type.strip()</span>
                    <span class="s1">charset = content_type_extra.get(</span><span class="s3">'charset'</span><span class="s1">)</span>

                    <span class="s2">try</span><span class="s1">:</span>
                        <span class="s1">content_length = int(meta_data.get(</span><span class="s3">'content-length'</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">])</span>
                    <span class="s2">except </span><span class="s1">(IndexError</span><span class="s2">, </span><span class="s1">TypeError</span><span class="s2">, </span><span class="s1">ValueError):</span>
                        <span class="s1">content_length = </span><span class="s2">None</span>

                    <span class="s1">counters = [</span><span class="s5">0</span><span class="s1">] * len(handlers)</span>
                    <span class="s1">uploaded_file = </span><span class="s2">False</span>
                    <span class="s2">try</span><span class="s1">:</span>
                        <span class="s2">for </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">handlers:</span>
                            <span class="s2">try</span><span class="s1">:</span>
                                <span class="s1">handler.new_file(</span>
                                    <span class="s1">field_name</span><span class="s2">, </span><span class="s1">file_name</span><span class="s2">, </span><span class="s1">content_type</span><span class="s2">,</span>
                                    <span class="s1">content_length</span><span class="s2">, </span><span class="s1">charset</span><span class="s2">, </span><span class="s1">content_type_extra</span><span class="s2">,</span>
                                <span class="s1">)</span>
                            <span class="s2">except </span><span class="s1">StopFutureHandlers:</span>
                                <span class="s2">break</span>

                        <span class="s2">for </span><span class="s1">chunk </span><span class="s2">in </span><span class="s1">field_stream:</span>
                            <span class="s2">if </span><span class="s1">transfer_encoding == </span><span class="s3">'base64'</span><span class="s1">:</span>
                                <span class="s4"># We only special-case base64 transfer encoding</span>
                                <span class="s4"># We should always decode base64 chunks by multiple of 4,</span>
                                <span class="s4"># ignoring whitespace.</span>

                                <span class="s1">stripped_chunk = </span><span class="s6">b&quot;&quot;</span><span class="s1">.join(chunk.split())</span>

                                <span class="s1">remaining = len(stripped_chunk) % </span><span class="s5">4</span>
                                <span class="s2">while </span><span class="s1">remaining != </span><span class="s5">0</span><span class="s1">:</span>
                                    <span class="s1">over_chunk = field_stream.read(</span><span class="s5">4 </span><span class="s1">- remaining)</span>
                                    <span class="s1">stripped_chunk += </span><span class="s6">b&quot;&quot;</span><span class="s1">.join(over_chunk.split())</span>
                                    <span class="s1">remaining = len(stripped_chunk) % </span><span class="s5">4</span>

                                <span class="s2">try</span><span class="s1">:</span>
                                    <span class="s1">chunk = base64.b64decode(stripped_chunk)</span>
                                <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">exc:</span>
                                    <span class="s4"># Since this is only a chunk, any error is an unfixable error.</span>
                                    <span class="s2">raise </span><span class="s1">MultiPartParserError(</span><span class="s3">&quot;Could not decode base64 data.&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">exc</span>

                            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">enumerate(handlers):</span>
                                <span class="s1">chunk_length = len(chunk)</span>
                                <span class="s1">chunk = handler.receive_data_chunk(chunk</span><span class="s2">, </span><span class="s1">counters[i])</span>
                                <span class="s1">counters[i] += chunk_length</span>
                                <span class="s2">if </span><span class="s1">chunk </span><span class="s2">is None</span><span class="s1">:</span>
                                    <span class="s4"># Don't continue if the chunk received by</span>
                                    <span class="s4"># the handler is None.</span>
                                    <span class="s2">break</span>

                    <span class="s2">except </span><span class="s1">SkipFile:</span>
                        <span class="s1">self._close_files()</span>
                        <span class="s4"># Just use up the rest of this file...</span>
                        <span class="s1">exhaust(field_stream)</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s4"># Handle file upload completions on next iteration.</span>
                        <span class="s1">old_field_name = field_name</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s4"># If this is neither a FIELD or a FILE, just exhaust the stream.</span>
                    <span class="s1">exhaust(stream)</span>
        <span class="s2">except </span><span class="s1">StopUpload </span><span class="s2">as </span><span class="s1">e:</span>
            <span class="s1">self._close_files()</span>
            <span class="s2">if not </span><span class="s1">e.connection_reset:</span>
                <span class="s1">exhaust(self._input_data)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">uploaded_file:</span>
                <span class="s2">for </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">handlers:</span>
                    <span class="s1">handler.upload_interrupted()</span>
            <span class="s4"># Make sure that the request data is all fed</span>
            <span class="s1">exhaust(self._input_data)</span>

        <span class="s4"># Signal that the upload has completed.</span>
        <span class="s4"># any() shortcircuits if a handler's upload_complete() returns a value.</span>
        <span class="s1">any(handler.upload_complete() </span><span class="s2">for </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">handlers)</span>
        <span class="s1">self._post._mutable = </span><span class="s2">False</span>
        <span class="s2">return </span><span class="s1">self._post</span><span class="s2">, </span><span class="s1">self._files</span>

    <span class="s2">def </span><span class="s1">handle_file_complete(self</span><span class="s2">, </span><span class="s1">old_field_name</span><span class="s2">, </span><span class="s1">counters):</span>
        <span class="s0">&quot;&quot;&quot; 
        Handle all the signaling that takes place when a file is complete. 
        &quot;&quot;&quot;</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">enumerate(self._upload_handlers):</span>
            <span class="s1">file_obj = handler.file_complete(counters[i])</span>
            <span class="s2">if </span><span class="s1">file_obj:</span>
                <span class="s4"># If it returns a file object, then set the files dict.</span>
                <span class="s1">self._files.appendlist(force_str(old_field_name</span><span class="s2">, </span><span class="s1">self._encoding</span><span class="s2">, </span><span class="s1">errors=</span><span class="s3">'replace'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">file_obj)</span>
                <span class="s2">break</span>

    <span class="s2">def </span><span class="s1">sanitize_file_name(self</span><span class="s2">, </span><span class="s1">file_name):</span>
        <span class="s0">&quot;&quot;&quot; 
        Sanitize the filename of an upload. 
 
        Remove all possible path separators, even though that might remove more 
        than actually required by the target system. Filenames that could 
        potentially cause problems (current/parent dir) are also discarded. 
 
        It should be noted that this function could still return a &quot;filepath&quot; 
        like &quot;C:some_file.txt&quot; which is handled later on by the storage layer. 
        So while this function does sanitize filenames to some extent, the 
        resulting filename should still be considered as untrusted user input. 
        &quot;&quot;&quot;</span>
        <span class="s1">file_name = html.unescape(file_name)</span>
        <span class="s1">file_name = file_name.rsplit(</span><span class="s3">'/'</span><span class="s1">)[-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">file_name = file_name.rsplit(</span><span class="s3">'</span><span class="s2">\\</span><span class="s3">'</span><span class="s1">)[-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">file_name </span><span class="s2">in </span><span class="s1">{</span><span class="s3">''</span><span class="s2">, </span><span class="s3">'.'</span><span class="s2">, </span><span class="s3">'..'</span><span class="s1">}:</span>
            <span class="s2">return None</span>
        <span class="s2">return </span><span class="s1">file_name</span>

    <span class="s1">IE_sanitize = sanitize_file_name</span>

    <span class="s2">def </span><span class="s1">_close_files(self):</span>
        <span class="s4"># Free up all file handles.</span>
        <span class="s4"># FIXME: this currently assumes that upload handlers store the file as 'file'</span>
        <span class="s4"># We should document that... (Maybe add handler.free_file to complement new_file)</span>
        <span class="s2">for </span><span class="s1">handler </span><span class="s2">in </span><span class="s1">self._upload_handlers:</span>
            <span class="s2">if </span><span class="s1">hasattr(handler</span><span class="s2">, </span><span class="s3">'file'</span><span class="s1">):</span>
                <span class="s1">handler.file.close()</span>


<span class="s2">class </span><span class="s1">LazyStream:</span>
    <span class="s0">&quot;&quot;&quot; 
    The LazyStream wrapper allows one to get and &quot;unget&quot; bytes from a stream. 
 
    Given a producer object (an iterator that yields bytestrings), the 
    LazyStream object will support iteration, reading, and keeping a &quot;look-back&quot; 
    variable in case you need to &quot;unget&quot; some bytes. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">producer</span><span class="s2">, </span><span class="s1">length=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Every LazyStream must have a producer when instantiated. 
 
        A producer is an iterable that returns a string each time it 
        is called. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._producer = producer</span>
        <span class="s1">self._empty = </span><span class="s2">False</span>
        <span class="s1">self._leftover = </span><span class="s6">b''</span>
        <span class="s1">self.length = length</span>
        <span class="s1">self.position = </span><span class="s5">0</span>
        <span class="s1">self._remaining = length</span>
        <span class="s1">self._unget_history = []</span>

    <span class="s2">def </span><span class="s1">tell(self):</span>
        <span class="s2">return </span><span class="s1">self.position</span>

    <span class="s2">def </span><span class="s1">read(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">def </span><span class="s1">parts():</span>
            <span class="s1">remaining = self._remaining </span><span class="s2">if </span><span class="s1">size </span><span class="s2">is None else </span><span class="s1">size</span>
            <span class="s4"># do the whole thing in one shot if no limit was provided.</span>
            <span class="s2">if </span><span class="s1">remaining </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">yield </span><span class="s6">b''</span><span class="s1">.join(self)</span>
                <span class="s2">return</span>

            <span class="s4"># otherwise do some bookkeeping to return exactly enough</span>
            <span class="s4"># of the stream and stashing any extra content we get from</span>
            <span class="s4"># the producer</span>
            <span class="s2">while </span><span class="s1">remaining != </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">assert </span><span class="s1">remaining &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s3">'remaining bytes to read should never go negative'</span>

                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">chunk = next(self)</span>
                <span class="s2">except </span><span class="s1">StopIteration:</span>
                    <span class="s2">return</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">emitting = chunk[:remaining]</span>
                    <span class="s1">self.unget(chunk[remaining:])</span>
                    <span class="s1">remaining -= len(emitting)</span>
                    <span class="s2">yield </span><span class="s1">emitting</span>

        <span class="s2">return </span><span class="s6">b''</span><span class="s1">.join(parts())</span>

    <span class="s2">def </span><span class="s1">__next__(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Used when the exact number of bytes to read is unimportant. 
 
        Return whatever chunk is conveniently returned from the iterator. 
        Useful to avoid unnecessary bookkeeping if performance is an issue. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._leftover:</span>
            <span class="s1">output = self._leftover</span>
            <span class="s1">self._leftover = </span><span class="s6">b''</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">output = next(self._producer)</span>
            <span class="s1">self._unget_history = []</span>
        <span class="s1">self.position += len(output)</span>
        <span class="s2">return </span><span class="s1">output</span>

    <span class="s2">def </span><span class="s1">close(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Used to invalidate/disable this lazy stream. 
 
        Replace the producer with an empty list. Any leftover bytes that have 
        already been read will still be reported upon read() and/or next(). 
        &quot;&quot;&quot;</span>
        <span class="s1">self._producer = []</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">unget(self</span><span class="s2">, </span><span class="s1">bytes):</span>
        <span class="s0">&quot;&quot;&quot; 
        Place bytes back onto the front of the lazy stream. 
 
        Future calls to read() will return those bytes first. The 
        stream position and thus tell() will be rewound. 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">bytes:</span>
            <span class="s2">return</span>
        <span class="s1">self._update_unget_history(len(bytes))</span>
        <span class="s1">self.position -= len(bytes)</span>
        <span class="s1">self._leftover = bytes + self._leftover</span>

    <span class="s2">def </span><span class="s1">_update_unget_history(self</span><span class="s2">, </span><span class="s1">num_bytes):</span>
        <span class="s0">&quot;&quot;&quot; 
        Update the unget history as a sanity check to see if we've pushed 
        back the same number of bytes in one chunk. If we keep ungetting the 
        same number of bytes many times (here, 50), we're mostly likely in an 
        infinite loop of some sort. This is usually caused by a 
        maliciously-malformed MIME request. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._unget_history = [num_bytes] + self._unget_history[:</span><span class="s5">49</span><span class="s1">]</span>
        <span class="s1">number_equal = len([</span>
            <span class="s1">current_number </span><span class="s2">for </span><span class="s1">current_number </span><span class="s2">in </span><span class="s1">self._unget_history</span>
            <span class="s2">if </span><span class="s1">current_number == num_bytes</span>
        <span class="s1">])</span>

        <span class="s2">if </span><span class="s1">number_equal &gt; </span><span class="s5">40</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">SuspiciousMultipartForm(</span>
                <span class="s3">&quot;The multipart parser got stuck, which shouldn't happen with&quot;</span>
                <span class="s3">&quot; normal uploaded files. Check for malicious upload activity;&quot;</span>
                <span class="s3">&quot; if there is none, report this to the Django developers.&quot;</span>
            <span class="s1">)</span>


<span class="s2">class </span><span class="s1">ChunkIter:</span>
    <span class="s0">&quot;&quot;&quot; 
    An iterable that will yield chunks of data. Given a file-like object as the 
    constructor, yield chunks of read operations from that object. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">flo</span><span class="s2">, </span><span class="s1">chunk_size=</span><span class="s5">64 </span><span class="s1">* </span><span class="s5">1024</span><span class="s1">):</span>
        <span class="s1">self.flo = flo</span>
        <span class="s1">self.chunk_size = chunk_size</span>

    <span class="s2">def </span><span class="s1">__next__(self):</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">data = self.flo.read(self.chunk_size)</span>
        <span class="s2">except </span><span class="s1">InputStreamExhausted:</span>
            <span class="s2">raise </span><span class="s1">StopIteration()</span>
        <span class="s2">if </span><span class="s1">data:</span>
            <span class="s2">return </span><span class="s1">data</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">StopIteration()</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>


<span class="s2">class </span><span class="s1">InterBoundaryIter:</span>
    <span class="s0">&quot;&quot;&quot; 
    A Producer that will iterate over boundaries. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">stream</span><span class="s2">, </span><span class="s1">boundary):</span>
        <span class="s1">self._stream = stream</span>
        <span class="s1">self._boundary = boundary</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__next__(self):</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">LazyStream(BoundaryIter(self._stream</span><span class="s2">, </span><span class="s1">self._boundary))</span>
        <span class="s2">except </span><span class="s1">InputStreamExhausted:</span>
            <span class="s2">raise </span><span class="s1">StopIteration()</span>


<span class="s2">class </span><span class="s1">BoundaryIter:</span>
    <span class="s0">&quot;&quot;&quot; 
    A Producer that is sensitive to boundaries. 
 
    Will happily yield bytes until a boundary is found. Will yield the bytes 
    before the boundary, throw away the boundary bytes themselves, and push the 
    post-boundary bytes back on the stream. 
 
    The future calls to next() after locating the boundary will raise a 
    StopIteration exception. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">stream</span><span class="s2">, </span><span class="s1">boundary):</span>
        <span class="s1">self._stream = stream</span>
        <span class="s1">self._boundary = boundary</span>
        <span class="s1">self._done = </span><span class="s2">False</span>
        <span class="s4"># rollback an additional six bytes because the format is like</span>
        <span class="s4"># this: CRLF&lt;boundary&gt;[--CRLF]</span>
        <span class="s1">self._rollback = len(boundary) + </span><span class="s5">6</span>

        <span class="s4"># Try to use mx fast string search if available. Otherwise</span>
        <span class="s4"># use Python find. Wrap the latter for consistency.</span>
        <span class="s1">unused_char = self._stream.read(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">unused_char:</span>
            <span class="s2">raise </span><span class="s1">InputStreamExhausted()</span>
        <span class="s1">self._stream.unget(unused_char)</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__next__(self):</span>
        <span class="s2">if </span><span class="s1">self._done:</span>
            <span class="s2">raise </span><span class="s1">StopIteration()</span>

        <span class="s1">stream = self._stream</span>
        <span class="s1">rollback = self._rollback</span>

        <span class="s1">bytes_read = </span><span class="s5">0</span>
        <span class="s1">chunks = []</span>
        <span class="s2">for </span><span class="s1">bytes </span><span class="s2">in </span><span class="s1">stream:</span>
            <span class="s1">bytes_read += len(bytes)</span>
            <span class="s1">chunks.append(bytes)</span>
            <span class="s2">if </span><span class="s1">bytes_read &gt; rollback:</span>
                <span class="s2">break</span>
            <span class="s2">if not </span><span class="s1">bytes:</span>
                <span class="s2">break</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._done = </span><span class="s2">True</span>

        <span class="s2">if not </span><span class="s1">chunks:</span>
            <span class="s2">raise </span><span class="s1">StopIteration()</span>

        <span class="s1">chunk = </span><span class="s6">b''</span><span class="s1">.join(chunks)</span>
        <span class="s1">boundary = self._find_boundary(chunk)</span>

        <span class="s2">if </span><span class="s1">boundary:</span>
            <span class="s1">end</span><span class="s2">, </span><span class="s1">next = boundary</span>
            <span class="s1">stream.unget(chunk[next:])</span>
            <span class="s1">self._done = </span><span class="s2">True</span>
            <span class="s2">return </span><span class="s1">chunk[:end]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># make sure we don't treat a partial boundary (and</span>
            <span class="s4"># its separators) as data</span>
            <span class="s2">if not </span><span class="s1">chunk[:-rollback]:  </span><span class="s4"># and len(chunk) &gt;= (len(self._boundary) + 6):</span>
                <span class="s4"># There's nothing left, we should just return and mark as done.</span>
                <span class="s1">self._done = </span><span class="s2">True</span>
                <span class="s2">return </span><span class="s1">chunk</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">stream.unget(chunk[-rollback:])</span>
                <span class="s2">return </span><span class="s1">chunk[:-rollback]</span>

    <span class="s2">def </span><span class="s1">_find_boundary(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0">&quot;&quot;&quot; 
        Find a multipart boundary in data. 
 
        Should no boundary exist in the data, return None. Otherwise, return 
        a tuple containing the indices of the following: 
         * the end of current encapsulation 
         * the start of the next encapsulation 
        &quot;&quot;&quot;</span>
        <span class="s1">index = data.find(self._boundary)</span>
        <span class="s2">if </span><span class="s1">index &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">end = index</span>
            <span class="s1">next = index + len(self._boundary)</span>
            <span class="s4"># backup over CRLF</span>
            <span class="s1">last = max(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">end - </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">data[last:last + </span><span class="s5">1</span><span class="s1">] == </span><span class="s6">b'</span><span class="s2">\n</span><span class="s6">'</span><span class="s1">:</span>
                <span class="s1">end -= </span><span class="s5">1</span>
            <span class="s1">last = max(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">end - </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">data[last:last + </span><span class="s5">1</span><span class="s1">] == </span><span class="s6">b'</span><span class="s2">\r</span><span class="s6">'</span><span class="s1">:</span>
                <span class="s1">end -= </span><span class="s5">1</span>
            <span class="s2">return </span><span class="s1">end</span><span class="s2">, </span><span class="s1">next</span>


<span class="s2">def </span><span class="s1">exhaust(stream_or_iterable):</span>
    <span class="s0">&quot;&quot;&quot;Exhaust an iterator or stream.&quot;&quot;&quot;</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">iterator = iter(stream_or_iterable)</span>
    <span class="s2">except </span><span class="s1">TypeError:</span>
        <span class="s1">iterator = ChunkIter(stream_or_iterable</span><span class="s2">, </span><span class="s5">16384</span><span class="s1">)</span>
    <span class="s1">collections.deque(iterator</span><span class="s2">, </span><span class="s1">maxlen=</span><span class="s5">0</span><span class="s1">)  </span><span class="s4"># consume iterator quickly.</span>


<span class="s2">def </span><span class="s1">parse_boundary_stream(stream</span><span class="s2">, </span><span class="s1">max_header_size):</span>
    <span class="s0">&quot;&quot;&quot; 
    Parse one and exactly one stream that encapsulates a boundary. 
    &quot;&quot;&quot;</span>
    <span class="s4"># Stream at beginning of header, look for end of header</span>
    <span class="s4"># and parse it if found. The header must fit within one</span>
    <span class="s4"># chunk.</span>
    <span class="s1">chunk = stream.read(max_header_size)</span>

    <span class="s4"># 'find' returns the top of these four bytes, so we'll</span>
    <span class="s4"># need to munch them later to prevent them from polluting</span>
    <span class="s4"># the payload.</span>
    <span class="s1">header_end = chunk.find(</span><span class="s6">b'</span><span class="s2">\r\n\r\n</span><span class="s6">'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_parse_header(line):</span>
        <span class="s1">main_value_pair</span><span class="s2">, </span><span class="s1">params = parse_header(line)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">value = main_value_pair.split(</span><span class="s3">':'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">except </span><span class="s1">ValueError:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Invalid header: %r&quot; </span><span class="s1">% line)</span>
        <span class="s2">return </span><span class="s1">name</span><span class="s2">, </span><span class="s1">(value</span><span class="s2">, </span><span class="s1">params)</span>

    <span class="s2">if </span><span class="s1">header_end == -</span><span class="s5">1</span><span class="s1">:</span>
        <span class="s4"># we find no header, so we just mark this fact and pass on</span>
        <span class="s4"># the stream verbatim</span>
        <span class="s1">stream.unget(chunk)</span>
        <span class="s2">return </span><span class="s1">(RAW</span><span class="s2">, </span><span class="s1">{}</span><span class="s2">, </span><span class="s1">stream)</span>

    <span class="s1">header = chunk[:header_end]</span>

    <span class="s4"># here we place any excess chunk back onto the stream, as</span>
    <span class="s4"># well as throwing away the CRLFCRLF bytes from above.</span>
    <span class="s1">stream.unget(chunk[header_end + </span><span class="s5">4</span><span class="s1">:])</span>

    <span class="s1">TYPE = RAW</span>
    <span class="s1">outdict = {}</span>

    <span class="s4"># Eliminate blank lines</span>
    <span class="s2">for </span><span class="s1">line </span><span class="s2">in </span><span class="s1">header.split(</span><span class="s6">b'</span><span class="s2">\r\n</span><span class="s6">'</span><span class="s1">):</span>
        <span class="s4"># This terminology (&quot;main value&quot; and &quot;dictionary of</span>
        <span class="s4"># parameters&quot;) is from the Python docs.</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">(value</span><span class="s2">, </span><span class="s1">params) = _parse_header(line)</span>
        <span class="s2">except </span><span class="s1">ValueError:</span>
            <span class="s2">continue</span>

        <span class="s2">if </span><span class="s1">name == </span><span class="s3">'content-disposition'</span><span class="s1">:</span>
            <span class="s1">TYPE = FIELD</span>
            <span class="s2">if </span><span class="s1">params.get(</span><span class="s3">'filename'</span><span class="s1">):</span>
                <span class="s1">TYPE = FILE</span>

        <span class="s1">outdict[name] = value</span><span class="s2">, </span><span class="s1">params</span>

    <span class="s2">if </span><span class="s1">TYPE == RAW:</span>
        <span class="s1">stream.unget(chunk)</span>

    <span class="s2">return </span><span class="s1">(TYPE</span><span class="s2">, </span><span class="s1">outdict</span><span class="s2">, </span><span class="s1">stream)</span>


<span class="s2">class </span><span class="s1">Parser:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">stream</span><span class="s2">, </span><span class="s1">boundary):</span>
        <span class="s1">self._stream = stream</span>
        <span class="s1">self._separator = </span><span class="s6">b'--' </span><span class="s1">+ boundary</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s1">boundarystream = InterBoundaryIter(self._stream</span><span class="s2">, </span><span class="s1">self._separator)</span>
        <span class="s2">for </span><span class="s1">sub_stream </span><span class="s2">in </span><span class="s1">boundarystream:</span>
            <span class="s4"># Iterate over each part</span>
            <span class="s2">yield </span><span class="s1">parse_boundary_stream(sub_stream</span><span class="s2">, </span><span class="s5">1024</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">parse_header(line):</span>
    <span class="s0">&quot;&quot;&quot; 
    Parse the header into a key-value. 
 
    Input (line): bytes, output: str for key/name, bytes for values which 
    will be decoded later. 
    &quot;&quot;&quot;</span>
    <span class="s1">plist = _parse_header_params(</span><span class="s6">b';' </span><span class="s1">+ line)</span>
    <span class="s1">key = plist.pop(</span><span class="s5">0</span><span class="s1">).lower().decode(</span><span class="s3">'ascii'</span><span class="s1">)</span>
    <span class="s1">pdict = {}</span>
    <span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">plist:</span>
        <span class="s1">i = p.find(</span><span class="s6">b'='</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">i &gt;= </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">has_encoding = </span><span class="s2">False</span>
            <span class="s1">name = p[:i].strip().lower().decode(</span><span class="s3">'ascii'</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">name.endswith(</span><span class="s3">'*'</span><span class="s1">):</span>
                <span class="s4"># Lang/encoding embedded in the value (like &quot;filename*=UTF-8''file.ext&quot;)</span>
                <span class="s4"># http://tools.ietf.org/html/rfc2231#section-4</span>
                <span class="s1">name = name[:-</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s2">if </span><span class="s1">p.count(</span><span class="s6">b&quot;'&quot;</span><span class="s1">) == </span><span class="s5">2</span><span class="s1">:</span>
                    <span class="s1">has_encoding = </span><span class="s2">True</span>
            <span class="s1">value = p[i + </span><span class="s5">1</span><span class="s1">:].strip()</span>
            <span class="s2">if </span><span class="s1">len(value) &gt;= </span><span class="s5">2 </span><span class="s2">and </span><span class="s1">value[:</span><span class="s5">1</span><span class="s1">] == value[-</span><span class="s5">1</span><span class="s1">:] == </span><span class="s6">b'&quot;'</span><span class="s1">:</span>
                <span class="s1">value = value[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">value = value.replace(</span><span class="s6">b'</span><span class="s2">\\\\</span><span class="s6">'</span><span class="s2">, </span><span class="s6">b'</span><span class="s2">\\</span><span class="s6">'</span><span class="s1">).replace(</span><span class="s6">b'</span><span class="s2">\\</span><span class="s6">&quot;'</span><span class="s2">, </span><span class="s6">b'&quot;'</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">has_encoding:</span>
                <span class="s1">encoding</span><span class="s2">, </span><span class="s1">lang</span><span class="s2">, </span><span class="s1">value = value.split(</span><span class="s6">b&quot;'&quot;</span><span class="s1">)</span>
                <span class="s1">value = unquote(value.decode()</span><span class="s2">, </span><span class="s1">encoding=encoding.decode())</span>
            <span class="s1">pdict[name] = value</span>
    <span class="s2">return </span><span class="s1">key</span><span class="s2">, </span><span class="s1">pdict</span>


<span class="s2">def </span><span class="s1">_parse_header_params(s):</span>
    <span class="s1">plist = []</span>
    <span class="s2">while </span><span class="s1">s[:</span><span class="s5">1</span><span class="s1">] == </span><span class="s6">b';'</span><span class="s1">:</span>
        <span class="s1">s = s[</span><span class="s5">1</span><span class="s1">:]</span>
        <span class="s1">end = s.find(</span><span class="s6">b';'</span><span class="s1">)</span>
        <span class="s2">while </span><span class="s1">end &gt; </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">s.count(</span><span class="s6">b'&quot;'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">end) % </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">end = s.find(</span><span class="s6">b';'</span><span class="s2">, </span><span class="s1">end + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">end &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">end = len(s)</span>
        <span class="s1">f = s[:end]</span>
        <span class="s1">plist.append(f.strip())</span>
        <span class="s1">s = s[end:]</span>
    <span class="s2">return </span><span class="s1">plist</span>
</pre>
</body>
</html>